apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: accounts
  namespace: fastly-metrics
spec:
  groups:
  - name: account
    rules:

    ##
    ## Basic Transformations
    ## - counter -> rate
    ## - histogram -> latency
    ## - etc
    ##

    - record: fastly_account:requests
      expr: sum(rate(fastly_rt_requests_total[120s]))
    - record: fastly_account:4xx_ratio
      expr: |
        sum(rate(fastly_rt_status_group_total{status_group="4xx"}[120s]))
        / sum(rate(fastly_rt_status_group_total[120s]))
    - record: fastly_account:5xx_ratio
      expr: |
        sum(rate(fastly_rt_status_group_total{status_group="5xx"}[120s]))
        / sum(rate(fastly_rt_status_group_total[120s]))
    - record: fastly_account:errors_ratio
      expr: |
        sum(rate(fastly_rt_errors_total[120s]))
        / fastly_account:requests
    - record: fastly_account:latency_p50_seconds
      expr: histogram_quantile(0.5,sum(rate(fastly_rt_miss_duration_seconds_bucket[120s])) by (le))
    - record: fastly_account:latency_p99_seconds
      expr: histogram_quantile(0.99,sum(rate(fastly_rt_miss_duration_seconds_bucket[120s])) by (le))

    ##
    ## Thresholds
    ## - Hysteresis, for more details see
    ##   https://promcon.io/2019-munich/talks/improved-alerting-with-prometheus-and-alertmanager/
    ##

    - record: fastly_account:4xx_warn_ratio
      expr: |
        0.0375+0*count(fastly_account:alerts_recently{alertname="fastlyAccount4xxPercent"})
        or 0.05+0*fastly_account:requests
    - record: fastly_account:5xx_warn_ratio
      expr: |
        0.0375+0*count(fastly_account:alerts_recently{alertname="fastlyAccount5xxPercent"})
        or 0.05+0*fastly_account:requests
    - record: fastly_account:errors_warn_ratio
      expr: |
        0.0375+0*count(fastly_account:alerts_recently{alertname="fastlyAccountErrorPercent"})
        or 0.05+0*fastly_account:requests
    # 826ms would put you in the worst 20% of sites
    # Per https://www.littledata.io/average/server-response-time
    - record: fastly_account:latency_p50_warn_seconds
      expr: |
        0.620+0*count(fastly_account:alerts_recently{alertname="fastlyAccountP50Latency"})
        or 0.826+0*fastly_account:requests
    # Our P50 latency, for example, tends to be less than one third of our P99 latency
    # Per https://medium.com/@djsmith42/how-to-metric-edafaf959fc7
    - record: fastly_account:latency_p99_warn_seconds
      expr: |
        1.859+0*count(fastly_account:alerts_recently{alertname="fastlyAccountP99Latency"})
        or 2.478+0*fastly_account:requests

    ##
    ## Alert Status
    ##

    - record: fastly_account:alerts
      expr: count(ALERTS{alertstate="firing"}) by (alertname)
    - record: fastly_account:alerts_recently
      expr: sum(sum_over_time(ALERTS{alertstate="firing"}[1h])) by (alertname)

    ##
    ## Criteria
    ##

    # Notice: some minimum level of traffic over time
    - record: fastly_account:criteria_notice
      expr: |
        min_over_time(fastly_account:requests[5m]) > 1
        and count_over_time(fastly_account:requests[5m]) > 2
    - record: fastly_account:criteria_notice_recently
      expr: count_over_time(fastly_account:criteria_notice[1h])

    # Warning: top 20% of notice
    - record: fastly_account:criteria_warning
      #expr: |
      #  topk(
      #    scalar(
      #      count(fastly_account:criteria_notice) * .2
      #    ), sum(fastly_account:criteria_notice)
      #  ) or count(fastly_account:alerts_recently)
      expr: |
        fastly_account:criteria_notice > scalar(
          sum(fastly_account:requests) * .01
        )
    - record: fastly_account:criteria_warning_recently
      expr: count_over_time(fastly_account:criteria_warning[1h])

    ##
    ## Alert Rules
    ## - Hold down timers / latch, for more details see
    ##   https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertmanagerFlapping
    ## - Example: max_over_time(min_over_time(fastly_account:4xx_ratio[3m])[10m:15s])
    ##   - Once the event persists for 3m
    ##   - Hold down / latch for 10m
    ##

    - alert: fastlyAccount4xxPercent
      expr: |
        (
          max_over_time(
            min_over_time(fastly_account:4xx_ratio[10m])[30m:15s]
          ) > fastly_account:4xx_warn_ratio



        )
      labels:
        job: 'fastlyAccount'
        severity: warning
      annotations:
        description: 'High ({{- $value | humanizePercentage }})'
    - alert: fastlyAccount5xxPercent
      expr: |
        (
          max_over_time(
            min_over_time(fastly_account:5xx_ratio[10m])[30m:15s]
          ) > fastly_account:5xx_warn_ratio



        )
      labels:
        job: 'fastlyAccount'
        severity: warning
      annotations:
        description: 'High ({{- $value | humanizePercentage }})'
    - alert: fastlyAccountErrorPercent
      expr: |
        (
          max_over_time(
            min_over_time(fastly_account:errors_ratio[10m])[30m:15s]
          ) > fastly_account:errors_warn_ratio



        )
      labels:
        job: 'fastlyAccount'
        severity: warning
      annotations:
        description: 'High ({{- $value | humanizePercentage }})'
    - alert: fastlyAccountP50Latency
      expr: |
        (
          max_over_time(
            min_over_time(fastly_account:latency_p50_seconds[10m])[30m:15s]
          ) > fastly_account:latency_p50_warn_seconds



        )
      labels:
        job: 'fastlyAccount'
        severity: warning
      annotations:
        description: 'High ({{- $value | humanizeDuration }})'
    - alert: fastlyAccountP99Latency
      expr: |
        (
          max_over_time(
            min_over_time(fastly_account:latency_p99_seconds[10m])[30m:15s]
          ) > fastly_account:latency_p99_warn_seconds



        )
      labels:
        job: 'fastlyAccount'
        severity: warning
      annotations:
        description: 'High ({{- $value | humanizeDuration }})'
